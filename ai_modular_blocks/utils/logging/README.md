# Logging Module

æ—¥å¿—ç³»ç»Ÿå®ç°

## ğŸ¯ æ¨¡å—è¯´æ˜

æä¾›ç»“æ„åŒ–æ—¥å¿—è®°å½•ã€æ€§èƒ½è¿½è¸ªã€é”™è¯¯åˆ†æç­‰åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼å’Œå¤„ç†å™¨ã€‚

## ğŸ“ æ–‡ä»¶ç»„ç»‡

### `formatters.py` - æ—¥å¿—æ ¼å¼åŒ–å™¨
- **JSONFormatter**: ç»“æ„åŒ–JSONæ—¥å¿—
- **ColoredFormatter**: å½©è‰²ç»ˆç«¯è¾“å‡º
- **CompactFormatter**: ç´§å‡‘æ ¼å¼æ—¥å¿—

### `handlers.py` - æ—¥å¿—å¤„ç†å™¨
- **AsyncFileHandler**: å¼‚æ­¥æ–‡ä»¶å†™å…¥
- **RotatingHandler**: æ–‡ä»¶è½®è½¬å¤„ç†
- **SlackHandler**: Slacké€šçŸ¥é›†æˆ
- **ElasticsearchHandler**: æ—¥å¿—æœç´¢é›†æˆ

### `filters.py` - æ—¥å¿—è¿‡æ»¤å™¨
- **SensitiveDataFilter**: æ•æ„Ÿä¿¡æ¯è¿‡æ»¤
- **LevelFilter**: æ—¥å¿—çº§åˆ«è¿‡æ»¤
- **RateLimitFilter**: é¢‘ç‡é™åˆ¶è¿‡æ»¤

### `config.py` - æ—¥å¿—é…ç½®ç®¡ç†
- **LoggingConfig**: æ—¥å¿—é…ç½®ç±»
- **setup_logging()**: æ—¥å¿—åˆå§‹åŒ–
- **get_logger()**: è·å–æ—¥å¿—å™¨

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

```python
from ai_modular_blocks.utils.logging import get_logger, LogContext

# è·å–æ—¥å¿—å™¨
logger = get_logger(__name__)

# ç»“æ„åŒ–æ—¥å¿—
logger.info(
    "LLM request completed",
    extra={
        "provider": "openai",
        "model": "gpt-3.5-turbo", 
        "tokens": 150,
        "duration_ms": 1200,
        "success": True
    }
)

# ä¸Šä¸‹æ–‡æ—¥å¿—
with LogContext(request_id="req123", user_id="user456"):
    logger.info("Processing request")  # è‡ªåŠ¨åŒ…å«context
    # ... ä¸šåŠ¡é€»è¾‘
    logger.info("Request completed")
```
