"""
004 - å¸¦å†å²è®°å½•çš„å¯¹è¯ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ç®¡ç†å¯¹è¯å†å²ï¼š
- ç”¨æˆ·è‡ªå®šä¹‰çš„å†å²ç®¡ç†ç­–ç•¥
- çº¯Pythonåˆ—è¡¨å’Œå­—å…¸ï¼Œæ— æ¡†æ¶æŠ½è±¡
- çµæ´»çš„ä¸Šä¸‹æ–‡çª—å£ç®¡ç†
- ä»…ä½¿ç”¨ deepseek
"""

import asyncio
import os
import json
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv
import sys

from ai_modular_blocks import create_llm, Message

load_dotenv()


class ConversationManager:
    """ç”¨æˆ·è‡ªå®šä¹‰çš„å¯¹è¯ç®¡ç†å™¨ - åªä½¿ç”¨ deepseek"""
    
    def __init__(self, max_history: int = 10):
        self.provider = "deepseek"
        self.llm = create_llm(
            self.provider,
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            temperature=0.7
        )
        
        # ç”¨æˆ·è‡ªå®šä¹‰çš„å†å²è®°å½•æ ¼å¼
        self.conversation_history: List[Dict[str, Any]] = []
        self.max_history = max_history
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        self.add_system_message(
            "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚ä½ ä¼šè®°ä½æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼Œ"
            "å¹¶æ ¹æ®ä¸Šä¸‹æ–‡æä¾›ç›¸å…³çš„å›å¤ã€‚"
        )
    
    def add_system_message(self, content: str):
        """æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯"""
        self.conversation_history.append({
            "role": "system",
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "type": "system"
        })
    
    def add_user_message(self, content: str):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        self.conversation_history.append({
            "role": "user", 
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "type": "user"
        })
    
    def add_assistant_message(self, content: str, metadata: Dict[str, Any] = None):
        """æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯"""
        message = {
            "role": "assistant",
            "content": content, 
            "timestamp": datetime.now().isoformat(),
            "type": "assistant",
            "provider": self.provider
        }
        
        if metadata:
            message["metadata"] = metadata
            
        self.conversation_history.append(message)
    
    def get_recent_messages(self, count: int = None) -> List[Message]:
        """è·å–æœ€è¿‘çš„æ¶ˆæ¯ï¼Œè½¬æ¢ä¸ºæ¡†æ¶æ ¼å¼"""
        count = count or self.max_history
        recent = self.conversation_history[-count:]
        
        return [
            Message(role=msg["role"], content=msg["content"])
            for msg in recent
        ]
    
    def manage_context_window(self):
        """ç®¡ç†ä¸Šä¸‹æ–‡çª—å£ - ç”¨æˆ·è‡ªå®šä¹‰çš„ç­–ç•¥"""
        if len(self.conversation_history) > self.max_history:
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
            system_messages = [msg for msg in self.conversation_history if msg["type"] == "system"]
            other_messages = [msg for msg in self.conversation_history if msg["type"] != "system"]
            
            # ä¿ç•™æœ€è¿‘çš„å¯¹è¯
            recent_messages = other_messages[-(self.max_history - len(system_messages)):]
            
            self.conversation_history = system_messages + recent_messages
            
            print(f"ğŸ”„ ä¸Šä¸‹æ–‡çª—å£ç®¡ç†: ä¿ç•™äº† {len(self.conversation_history)} æ¡æ¶ˆæ¯")
    
    async def chat(self, user_input: str) -> str:
        """è¿›è¡Œå¯¹è¯"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.add_user_message(user_input)
        
        # ç®¡ç†ä¸Šä¸‹æ–‡çª—å£
        self.manage_context_window()
        
        # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
        messages = self.get_recent_messages()
        
        try:
            # è°ƒç”¨LLM
            response = await self.llm.generate_from_messages(messages)
            answer = response["content"]
            
            # æ·»åŠ åŠ©æ‰‹å›å¤
            metadata = {
                "usage": response.usage,
                "model": response.model
            }
            self.add_assistant_message(answer, metadata)
            
            return answer
            
        except Exception as e:
            error_msg = f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼š{str(e)}"
            self.add_assistant_message(error_msg)
            return error_msg
    
    def show_conversation_summary(self):
        """æ˜¾ç¤ºå¯¹è¯æ‘˜è¦"""
        print("\nğŸ“Š å¯¹è¯æ‘˜è¦:")
        print(f"  æ€»æ¶ˆæ¯æ•°: {len(self.conversation_history)}")
        
        by_type = {}
        for msg in self.conversation_history:
            msg_type = msg["type"]
            by_type[msg_type] = by_type.get(msg_type, 0) + 1
        
        for msg_type, count in by_type.items():
            print(f"  {msg_type}: {count} æ¡")
    
    def export_conversation(self, filename: str):
        """å¯¼å‡ºå¯¹è¯å†å²"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f, 
                         ensure_ascii=False, indent=2)
            print(f"âœ… å¯¹è¯å†å²å·²å¯¼å‡ºåˆ°: {filename}")
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
    
    def load_conversation(self, filename: str):
        """åŠ è½½å¯¹è¯å†å²"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.conversation_history = json.load(f)
            print(f"âœ… å¯¹è¯å†å²å·²ä» {filename} åŠ è½½")
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")


async def demo_conversation_with_context():
    """æ¼”ç¤ºå¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯ï¼ˆåªç”¨ deepseekï¼‰"""
    print("ğŸš€ å¸¦å†å²è®°å½•çš„å¯¹è¯æ¼”ç¤º")
    print("=" * 50)
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„DEEPSEEK_API_KEY")
        return
    
    try:
        manager = ConversationManager(max_history=8)
        print(f"âœ… ä½¿ç”¨ Deepseek æä¾›å•†")
    except Exception as e:
        print(f"âŒ Deepseek åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æ¨¡æ‹Ÿä¸€ä¸ªæœ‰ä¸Šä¸‹æ–‡çš„å¯¹è¯
    conversation_flow = [
        "æˆ‘å«Aliceï¼Œæˆ‘æ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ",
        "æˆ‘æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€æ˜¯Python",
        "ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ",
        "æˆ‘åˆšæ‰è¯´æˆ‘å–œæ¬¢ä»€ä¹ˆç¼–ç¨‹è¯­è¨€ï¼Ÿ",
        "èƒ½æ¨èä¸€äº›Pythonçš„é«˜çº§ç‰¹æ€§ç»™æˆ‘å­¦ä¹ å—ï¼Ÿ",
        "è°¢è°¢ï¼ä½ è§‰å¾—è£…é¥°å™¨åœ¨å®é™…é¡¹ç›®ä¸­æœ‰ä»€ä¹ˆç”¨é€”ï¼Ÿ"
    ]
    
    print("\nğŸ­ æ¨¡æ‹Ÿå¯¹è¯æµç¨‹:")
    for i, user_message in enumerate(conversation_flow, 1):
        print(f"\nã€è½®æ¬¡ {i}ã€‘")
        print(f"ğŸ‘¤ Alice: {user_message}")
        
        response = await manager.chat(user_message)
        print(f"ğŸ¤– åŠ©æ‰‹: {response}")
        
        # æ˜¾ç¤ºå½“å‰å†å²è®°å½•æ•°é‡
        print(f"ğŸ’­ å½“å‰å†å²: {len(manager.conversation_history)} æ¡æ¶ˆæ¯")
        
        await asyncio.sleep(1)  # æ¨¡æ‹ŸçœŸå®å¯¹è¯é—´éš”
    
    # æ˜¾ç¤ºæœ€ç»ˆæ‘˜è¦
    manager.show_conversation_summary()
    
    # å¯¼å‡ºå¯¹è¯
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"conversation_{timestamp}.json"
    manager.export_conversation(filename)
    
    return manager


async def interactive_mode():
    """äº¤äº’æ¨¡å¼ï¼ˆåªç”¨ deepseekï¼‰"""
    print("\nğŸ® è¿›å…¥äº¤äº’æ¨¡å¼")
    print("ğŸ’¡ è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯æ‘˜è¦")
    print("ğŸ’¡ è¾“å…¥ 'export' å¯¼å‡ºå¯¹è¯å†å²") 
    print("ğŸ’¡ è¾“å…¥ 'quit' é€€å‡º")
    print("-" * 40)
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„DEEPSEEK_API_KEY")
        return
    
    try:
        manager = ConversationManager()
        print(f"âœ… ä½¿ç”¨ Deepseek å¼€å§‹å¯¹è¯")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
            
            if user_input.lower() == 'quit':
                break
            elif user_input.lower() == 'history':
                manager.show_conversation_summary()
                continue
            elif user_input.lower() == 'export':
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                manager.export_conversation(f"chat_{timestamp}.json")
                continue
            elif not user_input:
                continue
            
            response = await manager.chat(user_input)
            print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ å¯¹è¯å¼‚å¸¸: {e}")
    
    print("\nğŸ‘‹ å¯¹è¯ç»“æŸï¼")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ AI Modular Blocks - å¸¦å†å²è®°å½•çš„å¯¹è¯")
    print("å±•ç¤ºç”¨æˆ·è‡ªå®šä¹‰çš„å¯¹è¯å†å²ç®¡ç†ï¼ˆåªç”¨ deepseekï¼‰")
    print()
    
    # æ¼”ç¤ºæ¨¡å¼
    manager = await demo_conversation_with_context()
    
    if manager and sys.stdin.isatty():
        print(f"\nğŸ® æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼ï¼Ÿ(y/N)")
        try:
            choice = input().strip().lower()
            if choice in ['y', 'yes']:
                await interactive_mode()
        except KeyboardInterrupt:
            pass
    
    print("\nğŸ¯ æ ¸å¿ƒç‰¹ç‚¹:")
    print("- ç”¨æˆ·å®Œå…¨æ§åˆ¶å†å²è®°å½•çš„æ ¼å¼å’Œå­˜å‚¨")
    print("- çµæ´»çš„ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ç­–ç•¥")
    print("- æ”¯æŒå¯¹è¯å¯¼å‡ºå’ŒåŠ è½½åŠŸèƒ½")
    print("- ä»…ä½¿ç”¨ deepseek ä½œä¸º LLM æä¾›å•†")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
