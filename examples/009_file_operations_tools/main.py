#!/usr/bin/env python3

import asyncio
import os
import sys
sys.path.append('../..')

from ai_modular_blocks import create_llm
from ai_modular_blocks.tools import FileOperations

class CodeAnalysisAssistant:
    """
    ä»£ç åˆ†æåŠ©æ‰‹ - ç»“åˆLLMå’Œæ–‡ä»¶æ“ä½œå·¥å…·
    
    å±•ç¤ºå¦‚ä½•ç”¨çº¯Pythonç»„åˆä¸åŒå·¥å…·æ¥åˆ†æä»£ç åº“
    """
    
    def __init__(self, provider: str = "openai"):
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.file_ops = FileOperations()
    
    async def analyze_codebase(self, directory: str) -> dict:
        """åˆ†æä»£ç åº“ç»“æ„å’Œå†…å®¹"""
        
        print(f"ğŸ“‚ æ­£åœ¨åˆ†æä»£ç åº“: {directory}")
        
        # 1. åˆ—å‡ºæ‰€æœ‰Pythonæ–‡ä»¶
        python_files = []
        list_result = await self.file_ops.list_files(directory)
        
        if not list_result["success"]:
            return {"error": f"æ— æ³•è®¿é—®ç›®å½•: {list_result['error']}"}
        
        for file_path in list_result["files"]:
            if file_path.endswith('.py'):
                python_files.append(file_path)
        
        if not python_files:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°Pythonæ–‡ä»¶"}
        
        print(f"ğŸ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        
        # 2. è¯»å–æ–‡ä»¶å†…å®¹
        file_contents = {}
        total_lines = 0
        
        for file_path in python_files[:10]:  # é™åˆ¶æ–‡ä»¶æ•°é‡
            read_result = await self.file_ops.read_file(file_path)
            if read_result["success"]:
                content = read_result["content"]
                file_contents[file_path] = content
                total_lines += len(content.split('\n'))
        
        # 3. LLMåˆ†æä»£ç åº“
        files_summary = "\n\n".join([
            f"æ–‡ä»¶: {path}\n```python\n{content[:1000]}{'...' if len(content) > 1000 else ''}\n```"
            for path, content in file_contents.items()
        ])
        
        analysis_prompt = f"""
è¯·åˆ†æè¿™ä¸ªPythonä»£ç åº“:

æ€»è®¡ {len(python_files)} ä¸ªPythonæ–‡ä»¶ï¼Œ{total_lines} è¡Œä»£ç 

ä¸»è¦æ–‡ä»¶å†…å®¹:
{files_summary}

è¯·æä¾›ä»¥ä¸‹åˆ†æ:
1. ä»£ç åº“çš„ä¸»è¦åŠŸèƒ½å’Œç›®çš„
2. æ¶æ„è®¾è®¡ç‰¹ç‚¹
3. ä»£ç è´¨é‡è¯„ä¼°
4. å¯èƒ½çš„æ”¹è¿›å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´ä½†å…¨é¢ã€‚
"""
        
        print("ğŸ¤– æ­£åœ¨åˆ†æä»£ç ...")
        analysis = await self.llm.generate(analysis_prompt)
        
        return {
            "directory": directory,
            "total_files": len(python_files),
            "total_lines": total_lines,
            "analyzed_files": list(file_contents.keys()),
            "analysis": analysis["content"],
            "file_list": python_files
        }
    
    async def refactor_file(self, file_path: str, requirements: str) -> dict:
        """é‡æ„æŒ‡å®šæ–‡ä»¶"""
        
        print(f"ğŸ”§ æ­£åœ¨é‡æ„æ–‡ä»¶: {file_path}")
        
        # 1. è¯»å–åŸæ–‡ä»¶
        read_result = await self.file_ops.read_file(file_path)
        if not read_result["success"]:
            return {"error": f"æ— æ³•è¯»å–æ–‡ä»¶: {read_result['error']}"}
        
        original_content = read_result["content"]
        
        # 2. LLMç”Ÿæˆé‡æ„ä»£ç 
        refactor_prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚é‡æ„è¿™ä¸ªPythonæ–‡ä»¶:

é‡æ„è¦æ±‚: {requirements}

åŸå§‹ä»£ç :
```python
{original_content}
```

è¯·æä¾›é‡æ„åçš„å®Œæ•´ä»£ç ï¼Œä¿æŒåŠŸèƒ½ä¸å˜ä½†æ”¹è¿›ä»£ç è´¨é‡ã€‚
åªè¿”å›é‡æ„åçš„ä»£ç ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚
"""
        
        print("ğŸ¤– æ­£åœ¨ç”Ÿæˆé‡æ„ä»£ç ...")
        refactored_response = await self.llm.generate(refactor_prompt)
        
        # 3. åˆ›å»ºå¤‡ä»½å¹¶å†™å…¥æ–°ä»£ç 
        backup_path = f"{file_path}.backup"
        backup_result = await self.file_ops.write_file(backup_path, original_content)
        
        if not backup_result["success"]:
            return {"error": f"æ— æ³•åˆ›å»ºå¤‡ä»½: {backup_result['error']}"}
        
        # 4. å†™å…¥é‡æ„åçš„ä»£ç 
        refactored_code = refactored_response["content"]
        
        # æ¸…ç†ä»£ç å—æ ‡è®°
        if refactored_code.startswith('```python'):
            refactored_code = refactored_code[9:]
        if refactored_code.endswith('```'):
            refactored_code = refactored_code[:-3]
        refactored_code = refactored_code.strip()
        
        write_result = await self.file_ops.write_file(file_path, refactored_code)
        
        if not write_result["success"]:
            return {"error": f"æ— æ³•å†™å…¥æ–‡ä»¶: {write_result['error']}"}
        
        return {
            "file_path": file_path,
            "backup_path": backup_path,
            "original_lines": len(original_content.split('\n')),
            "refactored_lines": len(refactored_code.split('\n')),
            "requirements": requirements,
            "success": True
        }

class DocumentationGenerator:
    """æ–‡æ¡£ç”Ÿæˆå™¨ - è‡ªåŠ¨ä¸ºä»£ç ç”Ÿæˆæ–‡æ¡£"""
    
    def __init__(self, provider: str = "openai"):
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.file_ops = FileOperations()
    
    async def generate_readme(self, directory: str) -> dict:
        """ä¸ºé¡¹ç›®ç”ŸæˆREADME.md"""
        
        # 1. åˆ†æé¡¹ç›®ç»“æ„
        list_result = await self.file_ops.list_files(directory)
        if not list_result["success"]:
            return {"error": f"æ— æ³•è®¿é—®ç›®å½•: {list_result['error']}"}
        
        # 2. è¯»å–å…³é”®æ–‡ä»¶
        key_files = {}
        for filename in ['main.py', '__init__.py', 'setup.py', 'pyproject.toml']:
            file_path = os.path.join(directory, filename)
            read_result = await self.file_ops.read_file(file_path)
            if read_result["success"]:
                key_files[filename] = read_result["content"][:2000]
        
        # 3. ç”ŸæˆREADME
        files_info = "\n".join([f"{name}: {content[:500]}..." for name, content in key_files.items()])
        
        readme_prompt = f"""
åŸºäºä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„README.mdæ–‡ä»¶:

é¡¹ç›®ç›®å½•: {directory}
æ–‡ä»¶åˆ—è¡¨: {', '.join(list_result['files'][:20])}

å…³é”®æ–‡ä»¶å†…å®¹:
{files_info}

è¯·ç”Ÿæˆä¸€ä¸ªåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„README.md:
1. é¡¹ç›®æ ‡é¢˜å’Œç®€ä»‹
2. åŠŸèƒ½ç‰¹ç‚¹
3. å®‰è£…æ–¹æ³•
4. ä½¿ç”¨ç¤ºä¾‹
5. é¡¹ç›®ç»“æ„
6. è´¡çŒ®æŒ‡å—

ä½¿ç”¨Markdownæ ¼å¼ï¼Œä¿æŒä¸“ä¸šå’Œæ¸…æ™°ã€‚
"""
        
        readme_response = await self.llm.generate(readme_prompt)
        
        # 4. å†™å…¥READMEæ–‡ä»¶
        readme_path = os.path.join(directory, "README.md")
        write_result = await self.file_ops.write_file(readme_path, readme_response["content"])
        
        return {
            "readme_path": readme_path,
            "success": write_result["success"],
            "content": readme_response["content"][:500] + "...",
            "analyzed_files": list(key_files.keys())
        }

async def main():
    """æ¼”ç¤ºæ–‡ä»¶æ“ä½œå·¥å…·çš„ä½¿ç”¨"""
    
    # ç¤ºä¾‹1: ä»£ç åº“åˆ†æ
    print("=== ç¤ºä¾‹1: ä»£ç åº“åˆ†æ ===")
    analyzer = CodeAnalysisAssistant("openai")
    
    # åˆ†æå½“å‰é¡¹ç›®çš„ai_modular_blocksç›®å½•
    analysis_result = await analyzer.analyze_codebase("../../ai_modular_blocks")
    
    if "error" not in analysis_result:
        print(f"ğŸ“Š åˆ†æç»“æœ:")
        print(f"  ç›®å½•: {analysis_result['directory']}")
        print(f"  æ–‡ä»¶æ•°: {analysis_result['total_files']}")
        print(f"  ä»£ç è¡Œæ•°: {analysis_result['total_lines']}")
        print(f"ğŸ” ä»£ç åˆ†æ:\n{analysis_result['analysis'][:500]}...")
    else:
        print(f"âŒ åˆ†æå¤±è´¥: {analysis_result['error']}")
    
    print("\n" + "="*50 + "\n")
    
    # ç¤ºä¾‹2: æ–‡æ¡£ç”Ÿæˆ
    print("=== ç¤ºä¾‹2: è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆ ===")
    doc_gen = DocumentationGenerator("openai")
    
    readme_result = await doc_gen.generate_readme("../../ai_modular_blocks")
    
    if readme_result["success"]:
        print(f"ğŸ“ READMEç”ŸæˆæˆåŠŸ: {readme_result['readme_path']}")
        print(f"ğŸ“‹ å†…å®¹é¢„è§ˆ:\n{readme_result['content']}")
        print(f"ğŸ“ åˆ†æçš„æ–‡ä»¶: {', '.join(readme_result['analyzed_files'])}")
    else:
        print("âŒ READMEç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    asyncio.run(main())