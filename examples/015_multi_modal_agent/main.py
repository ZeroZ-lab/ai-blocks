#!/usr/bin/env python3

import asyncio
import json
import os
import sys
from typing import Dict, List, Any, Union

sys.path.append('../..')

from ai_modular_blocks import create_llm
from ai_modular_blocks.tools import Calculator, FileOperations, WebClient

class MultiModalAgent:
    """
    å¤šæ¨¡æ€ä»£ç† - å¤„ç†æ–‡æœ¬ã€æ•°æ®ã€ç½‘é¡µç­‰å¤šç§è¾“å…¥
    
    çº¯Pythonå®ç°ï¼Œå±•ç¤ºå¦‚ä½•ä¼˜é›…åœ°å¤„ç†ä¸åŒç±»å‹çš„ä»»åŠ¡
    """
    
    def __init__(self, provider: str = "openai"):
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.calculator = Calculator()
        self.file_ops = FileOperations()
        self.web_client = WebClient()
        
        # æ¨¡æ€å¤„ç†å™¨
        self.processors = {
            "text": self._process_text,
            "calculation": self._process_calculation,
            "file": self._process_file,
            "web": self._process_web,
            "data": self._process_data
        }
    
    async def understand_input(self, user_input: str, context: Dict = None) -> Dict:
        """ç†è§£è¾“å…¥çš„ç±»å‹å’Œæ„å›¾"""
        
        analysis_prompt = f"""
åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„ç±»å‹å’Œå¤„ç†æ–¹å¼:

è¾“å…¥: {user_input}
ä¸Šä¸‹æ–‡: {json.dumps(context or {}, ensure_ascii=False)}

è¯·åˆ¤æ–­è¿™ä¸ªè¾“å…¥éœ€è¦ä»€ä¹ˆç±»å‹çš„å¤„ç†:

è¿”å›JSON:
{{
  "primary_type": "text|calculation|file|web|data",
  "secondary_types": ["other_type1", "other_type2"],
  "intent": "å…·ä½“æ„å›¾æè¿°",
  "required_tools": ["tool1", "tool2"],
  "processing_strategy": "å¤„ç†ç­–ç•¥"
}}
"""
        
        response = await self.llm.generate(analysis_prompt)
        
        try:
            content = response["content"].strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            return json.loads(content)
        except:
            return {
                "primary_type": "text",
                "secondary_types": [],
                "intent": "é€šç”¨æ–‡æœ¬å¤„ç†",
                "required_tools": ["llm"],
                "processing_strategy": "è¯­è¨€æ¨¡å‹åˆ†æ"
            }
    
    async def process_multi_modal_input(self, user_input: str, context: Dict = None) -> Dict:
        """å¤„ç†å¤šæ¨¡æ€è¾“å…¥"""
        
        print(f"ğŸ” åˆ†æè¾“å…¥: {user_input}")
        
        # 1. ç†è§£è¾“å…¥ç±»å‹
        understanding = await self.understand_input(user_input, context)
        print(f"ğŸ“Š è¯†åˆ«ç±»å‹: {understanding['primary_type']}")
        print(f"ğŸ¯ å¤„ç†æ„å›¾: {understanding['intent']}")
        
        # 2. æ‰§è¡Œä¸»è¦å¤„ç†
        primary_result = await self.processors[understanding["primary_type"]](
            user_input, understanding
        )
        
        # 3. æ‰§è¡Œè¾…åŠ©å¤„ç†
        secondary_results = []
        for sec_type in understanding.get("secondary_types", []):
            if sec_type in self.processors and sec_type != understanding["primary_type"]:
                sec_result = await self.processors[sec_type](user_input, understanding)
                secondary_results.append({
                    "type": sec_type,
                    "result": sec_result
                })
        
        # 4. ç»¼åˆç»“æœ
        final_result = await self._synthesize_results(
            user_input, primary_result, secondary_results, understanding
        )
        
        return {
            "input": user_input,
            "understanding": understanding,
            "primary_result": primary_result,
            "secondary_results": secondary_results,
            "final_answer": final_result
        }
    
    async def _process_text(self, input_text: str, understanding: Dict) -> Dict:
        """å¤„ç†çº¯æ–‡æœ¬è¾“å…¥"""
        
        text_prompt = f"""
è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬è¯·æ±‚:

è¾“å…¥: {input_text}
æ„å›¾: {understanding['intent']}

æä¾›æœ‰ç”¨çš„å›ç­”æˆ–åˆ†æã€‚
"""
        
        response = await self.llm.generate(text_prompt)
        
        return {
            "type": "text_processing",
            "result": response["content"],
            "method": "LLMåˆ†æ"
        }
    
    async def _process_calculation(self, input_text: str, understanding: Dict) -> Dict:
        """å¤„ç†æ•°å­¦è®¡ç®—"""
        
        # æå–æ•°å­¦è¡¨è¾¾å¼
        extract_prompt = f"""
ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ•°å­¦è¡¨è¾¾å¼:

è¾“å…¥: {input_text}

è¿”å›ä¸€ä¸ªå¯ä»¥ç›´æ¥è®¡ç®—çš„è¡¨è¾¾å¼ï¼Œä¾‹å¦‚: 2+3*4
å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ•°å­¦è®¡ç®—ï¼Œè¿”å›: NONE
"""
        
        response = await self.llm.generate(extract_prompt)
        expression = response["content"].strip()
        
        if expression != "NONE" and expression:
            calc_result = self.calculator.calculate(expression)
            
            return {
                "type": "calculation",
                "expression": expression,
                "result": calc_result,
                "method": "æ•°å­¦è®¡ç®—å™¨"
            }
        
        return {
            "type": "calculation",
            "result": {"success": False, "error": "æœªæ‰¾åˆ°æ•°å­¦è¡¨è¾¾å¼"},
            "method": "è®¡ç®—å™¨"
        }
    
    async def _process_file(self, input_text: str, understanding: Dict) -> Dict:
        """å¤„ç†æ–‡ä»¶æ“ä½œ"""
        
        # ç®€åŒ–çš„æ–‡ä»¶æ“ä½œå¤„ç†
        if "è¯»å–" in input_text or "read" in input_text.lower():
            # æå–æ–‡ä»¶è·¯å¾„çš„ç®€å•é€»è¾‘
            words = input_text.split()
            potential_files = [w for w in words if '.' in w and '/' not in w[:3]]
            
            if potential_files:
                file_path = potential_files[0]
                read_result = await self.file_ops.read_file(file_path)
                
                return {
                    "type": "file_operation",
                    "operation": "read",
                    "file_path": file_path,
                    "result": read_result,
                    "method": "æ–‡ä»¶è¯»å–"
                }
        
        return {
            "type": "file_operation",
            "result": {"success": False, "error": "æ— æ³•ç¡®å®šæ–‡ä»¶æ“ä½œ"},
            "method": "æ–‡ä»¶æ“ä½œ"
        }
    
    async def _process_web(self, input_text: str, understanding: Dict) -> Dict:
        """å¤„ç†ç½‘é¡µç›¸å…³è¯·æ±‚"""
        
        # æå–URLçš„ç®€å•é€»è¾‘
        import re
        urls = re.findall(r'https?://[^\s]+', input_text)
        
        if urls:
            url = urls[0]
            web_result = await self.web_client.fetch(url)
            
            return {
                "type": "web_processing",
                "url": url,
                "result": web_result,
                "method": "ç½‘é¡µè·å–"
            }
        
        return {
            "type": "web_processing",
            "result": {"success": False, "error": "æœªæ‰¾åˆ°æœ‰æ•ˆURL"},
            "method": "ç½‘é¡µå¤„ç†"
        }
    
    async def _process_data(self, input_text: str, understanding: Dict) -> Dict:
        """å¤„ç†æ•°æ®åˆ†æè¯·æ±‚"""
        
        data_prompt = f"""
åˆ†æä»¥ä¸‹æ•°æ®ç›¸å…³è¯·æ±‚:

è¾“å…¥: {input_text}

è¯·æä¾›æ•°æ®åˆ†æçš„å»ºè®®æˆ–æ‰§è¡Œæ­¥éª¤ã€‚
"""
        
        response = await self.llm.generate(data_prompt)
        
        return {
            "type": "data_analysis",
            "result": response["content"],
            "method": "æ•°æ®åˆ†æ"
        }
    
    async def _synthesize_results(
        self, 
        input_text: str, 
        primary_result: Dict, 
        secondary_results: List[Dict], 
        understanding: Dict
    ) -> str:
        """ç»¼åˆæ‰€æœ‰ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”"""
        
        synthesis_prompt = f"""
ç”¨æˆ·è¾“å…¥: {input_text}
è¯†åˆ«æ„å›¾: {understanding['intent']}

ä¸»è¦å¤„ç†ç»“æœ:
{json.dumps(primary_result, ensure_ascii=False, indent=2)}

è¾…åŠ©å¤„ç†ç»“æœ:
{json.dumps(secondary_results, ensure_ascii=False, indent=2)}

è¯·åŸºäºä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªå®Œæ•´ã€æœ‰ç”¨çš„å›ç­”ã€‚
"""
        
        response = await self.llm.generate(synthesis_prompt)
        
        return response["content"]

# ä¸“é—¨çš„å¤šæ¨¡æ€åº”ç”¨å®ä¾‹
class PersonalAssistant:
    """ä¸ªäººåŠ©æ‰‹ - å¤šæ¨¡æ€ä»£ç†çš„åº”ç”¨å®ä¾‹"""
    
    def __init__(self, provider: str = "openai"):
        self.agent = MultiModalAgent(provider)
        self.session_context = {}
    
    async def handle_request(self, user_input: str) -> Dict:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚"""
        
        result = await self.agent.process_multi_modal_input(
            user_input, 
            self.session_context
        )
        
        # æ›´æ–°ä¼šè¯ä¸Šä¸‹æ–‡
        self.session_context["last_input"] = user_input
        self.session_context["last_result"] = result["final_answer"]
        
        return result
    
    async def analyze_document(self, file_path: str, question: str) -> Dict:
        """åˆ†ææ–‡æ¡£å¹¶å›ç­”é—®é¢˜"""
        
        combined_input = f"è¯·åˆ†ææ–‡ä»¶ {file_path} å¹¶å›ç­”: {question}"
        return await self.handle_request(combined_input)
    
    async def calculate_with_context(self, calculation: str, context: str) -> Dict:
        """åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­è¿›è¡Œè®¡ç®—"""
        
        combined_input = f"åœ¨ {context} çš„èƒŒæ™¯ä¸‹ï¼Œè¯·è®¡ç®—: {calculation}"
        return await self.handle_request(combined_input)

async def main():
    """æ¼”ç¤ºå¤šæ¨¡æ€ä»£ç†"""
    
    print("=== å¤šæ¨¡æ€ä»£ç†æ¼”ç¤º ===")
    
    assistant = PersonalAssistant("openai")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„è¾“å…¥
    test_cases = [
        "è®¡ç®— 25 * 4 + 10 çš„ç»“æœ",
        "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
        "å¦‚æœæˆ‘æœ‰10ä¸‡å…ƒæŠ•èµ„ï¼Œå¹´æ”¶ç›Šç‡6%ï¼Œ5å¹´åä¼šæœ‰å¤šå°‘é’±ï¼Ÿ",
        "è¯·è¯»å–æ–‡ä»¶ config.txt çš„å†…å®¹",
    ]
    
    print("æµ‹è¯•å¤šç§ç±»å‹çš„è¾“å…¥å¤„ç†...\n")
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"--- æµ‹è¯• {i} ---")
        
        result = await assistant.handle_request(test_input)
        
        print(f"ğŸ“¥ è¾“å…¥: {result['input']}")
        print(f"ğŸ§  ç†è§£: {result['understanding']['primary_type']} - {result['understanding']['intent']}")
        print(f"ğŸ“¤ å›ç­”: {result['final_answer'][:200]}...")
        
        if result['secondary_results']:
            print(f"ğŸ”§ è¾…åŠ©å¤„ç†: {len(result['secondary_results'])} ä¸ª")
        
        print()
    
    print("="*60)
    print("ğŸ¯ å¤šæ¨¡æ€å¤„ç†æ¼”ç¤ºå®Œæˆï¼")
    print("ä»£ç†èƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«ä¸åŒç±»å‹çš„è¾“å…¥å¹¶é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹å¼ã€‚")

if __name__ == "__main__":
    asyncio.run(main())