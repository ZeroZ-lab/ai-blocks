#!/usr/bin/env python3

import asyncio
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional

sys.path.append('../..')

from ai_modular_blocks import create_llm
from ai_modular_blocks.tools import Calculator, FileOperations

class Agent:
    """åŸºç¡€ä»£ç†ç±» - çº¯Pythonå®ç°"""
    
    def __init__(self, name: str, role: str, provider: str = "openai"):
        self.name = name
        self.role = role
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.capabilities = []
        self.message_queue = []
        self.collaboration_history = []
    
    async def process_message(self, message: Dict, context: Dict = None) -> Dict:
        """å¤„ç†æ¥è‡ªå…¶ä»–ä»£ç†çš„æ¶ˆæ¯"""
        
        response_prompt = f"""
ä½ æ˜¯ {self.name}ï¼Œè§’è‰²ï¼š{self.role}
ä½ çš„èƒ½åŠ›ï¼š{', '.join(self.capabilities)}

æ”¶åˆ°æ¶ˆæ¯ï¼š
å‘é€è€…ï¼š{message['from']}
ç±»å‹ï¼š{message['type']}
å†…å®¹ï¼š{message['content']}

ä¸Šä¸‹æ–‡ï¼š{json.dumps(context or {}, ensure_ascii=False)}

è¯·å¤„ç†è¿™ä¸ªæ¶ˆæ¯å¹¶æä¾›å›å¤ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
  "response": "ä½ çš„å›å¤å†…å®¹",
  "action_taken": "é‡‡å–çš„è¡ŒåŠ¨",
  "next_steps": "å»ºè®®çš„ä¸‹ä¸€æ­¥",
  "confidence": 0.9
}}
"""
        
        response = await self.llm.generate(response_prompt)
        
        try:
            content = response["content"].strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            result = json.loads(content)
            
            # è®°å½•åä½œå†å²
            self.collaboration_history.append({
                "timestamp": datetime.now().isoformat(),
                "type": "received_message",
                "from": message['from'],
                "message": message,
                "response": result
            })
            
            return result
            
        except:
            return {
                "response": f"æˆ‘æ˜¯{self.name}ï¼Œæ”¶åˆ°äº†ä½ çš„æ¶ˆæ¯ï¼Œæ­£åœ¨å¤„ç†ä¸­...",
                "action_taken": "æ¶ˆæ¯æ¥æ”¶",
                "next_steps": "ç­‰å¾…è¿›ä¸€æ­¥æŒ‡ä»¤",
                "confidence": 0.5
            }
    
    async def send_message(self, to_agent: 'Agent', message_type: str, content: str, context: Dict = None) -> Dict:
        """å‘å…¶ä»–ä»£ç†å‘é€æ¶ˆæ¯"""
        
        message = {
            "from": self.name,
            "to": to_agent.name,
            "type": message_type,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "context": context or {}
        }
        
        # å‘é€æ¶ˆæ¯å¹¶è·å–å“åº”
        response = await to_agent.process_message(message, context)
        
        # è®°å½•å‘é€å†å²
        self.collaboration_history.append({
            "timestamp": datetime.now().isoformat(),
            "type": "sent_message",
            "to": to_agent.name,
            "message": message,
            "response": response
        })
        
        return response

class DataAnalyst(Agent):
    """æ•°æ®åˆ†æå¸ˆä»£ç†"""
    
    def __init__(self, provider: str = "openai"):
        super().__init__("DataAnalyst", "æ•°æ®åˆ†æä¸“å®¶", provider)
        self.capabilities = ["æ•°æ®åˆ†æ", "ç»Ÿè®¡è®¡ç®—", "è¶‹åŠ¿è¯†åˆ«", "æŠ¥å‘Šç”Ÿæˆ"]
        self.calculator = Calculator()
    
    async def analyze_data(self, data: Dict) -> Dict:
        """åˆ†ææ•°æ®"""
        
        # æ‰§è¡Œä¸€äº›åŸºæœ¬ç»Ÿè®¡
        numbers = []
        if "values" in data:
            numbers = [float(x) for x in data["values"] if str(x).replace('.','').isdigit()]
        
        if numbers:
            total = sum(numbers)
            avg = total / len(numbers)
            max_val = max(numbers)
            min_val = min(numbers)
            
            analysis = {
                "count": len(numbers),
                "sum": total,
                "average": round(avg, 2),
                "max": max_val,
                "min": min_val,
                "range": max_val - min_val
            }
        else:
            analysis = {"error": "æ— æœ‰æ•ˆæ•°å€¼æ•°æ®"}
        
        return {
            "analyst": self.name,
            "analysis": analysis,
            "recommendations": ["éœ€è¦æ›´å¤šæ•°æ®", "å»ºè®®è¿›è¡Œæ·±å…¥åˆ†æ"],
            "timestamp": datetime.now().isoformat()
        }

class ProjectManager(Agent):
    """é¡¹ç›®ç»ç†ä»£ç†"""
    
    def __init__(self, provider: str = "openai"):
        super().__init__("ProjectManager", "é¡¹ç›®åè°ƒå’Œç®¡ç†", provider)
        self.capabilities = ["ä»»åŠ¡åˆ†é…", "è¿›åº¦è·Ÿè¸ª", "å›¢é˜Ÿåè°ƒ", "å†³ç­–åˆ¶å®š"]
        self.active_projects = []
    
    async def coordinate_project(self, project_goal: str, team_agents: List[Agent]) -> Dict:
        """åè°ƒé¡¹ç›®æ‰§è¡Œ"""
        
        print(f"ğŸ¯ é¡¹ç›®ç»ç†å¯åŠ¨é¡¹ç›®: {project_goal}")
        
        project = {
            "id": f"proj_{datetime.now().strftime('%H%M%S')}",
            "goal": project_goal,
            "team": [agent.name for agent in team_agents],
            "status": "active",
            "start_time": datetime.now().isoformat()
        }
        
        self.active_projects.append(project)
        
        # å‘å›¢é˜Ÿæˆå‘˜åˆ†é…ä»»åŠ¡
        coordination_results = []
        
        for agent in team_agents:
            task_assignment = await self.assign_task_to_agent(agent, project_goal, project)
            coordination_results.append({
                "agent": agent.name,
                "assignment": task_assignment
            })
            
            print(f"ğŸ“‹ å·²åˆ†é…ä»»åŠ¡ç»™ {agent.name}: {task_assignment['response'][:100]}...")
        
        return {
            "project": project,
            "assignments": coordination_results,
            "status": "é¡¹ç›®å·²å¯åŠ¨ï¼Œä»»åŠ¡å·²åˆ†é…"
        }
    
    async def assign_task_to_agent(self, agent: Agent, project_goal: str, project: Dict) -> Dict:
        """åˆ†é…ä»»åŠ¡ç»™ç‰¹å®šä»£ç†"""
        
        task_content = f"""
é¡¹ç›®ç›®æ ‡: {project_goal}
ä½ çš„è§’è‰²: {agent.role}
ä½ çš„èƒ½åŠ›: {', '.join(agent.capabilities)}

è¯·æ ¹æ®é¡¹ç›®ç›®æ ‡å’Œä½ çš„ä¸“é•¿ï¼Œåˆ¶å®šä½ è´Ÿè´£çš„å…·ä½“ä»»åŠ¡è®¡åˆ’ã€‚
"""
        
        return await self.send_message(
            agent, 
            "task_assignment", 
            task_content,
            {"project": project}
        )

class TechnicalExpert(Agent):
    """æŠ€æœ¯ä¸“å®¶ä»£ç†"""
    
    def __init__(self, provider: str = "openai"):
        super().__init__("TechnicalExpert", "æŠ€æœ¯å®ç°å’Œæ¶æ„è®¾è®¡", provider)
        self.capabilities = ["ç³»ç»Ÿè®¾è®¡", "æŠ€æœ¯é€‰å‹", "ä»£ç å®¡æŸ¥", "æ€§èƒ½ä¼˜åŒ–"]
        self.file_ops = FileOperations()
    
    async def design_solution(self, requirements: str) -> Dict:
        """è®¾è®¡æŠ€æœ¯æ–¹æ¡ˆ"""
        
        design_prompt = f"""
éœ€æ±‚: {requirements}

ä½œä¸ºæŠ€æœ¯ä¸“å®¶ï¼Œè¯·è®¾è®¡æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼š

è¿”å›JSON:
{{
  "architecture": "æ¶æ„è®¾è®¡æè¿°",
  "technologies": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
  "implementation_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
  "potential_challenges": ["æŒ‘æˆ˜1", "æŒ‘æˆ˜2"],
  "timeline_estimate": "æ—¶é—´ä¼°ç®—"
}}
"""
        
        response = await self.llm.generate(design_prompt)
        
        try:
            content = response["content"].strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            return json.loads(content)
        except:
            return {
                "architecture": "åŸºç¡€ä¸‰å±‚æ¶æ„",
                "technologies": ["Python", "æ•°æ®åº“"],
                "implementation_steps": ["éœ€æ±‚åˆ†æ", "è®¾è®¡", "å¼€å‘", "æµ‹è¯•"],
                "potential_challenges": ["æ€§èƒ½ä¼˜åŒ–", "æ‰©å±•æ€§"],
                "timeline_estimate": "4-6å‘¨"
            }

class MultiAgentSystem:
    """å¤šä»£ç†åä½œç³»ç»Ÿ"""
    
    def __init__(self):
        self.agents = {}
        self.message_history = []
        self.active_collaborations = []
    
    def add_agent(self, agent: Agent):
        """æ·»åŠ ä»£ç†åˆ°ç³»ç»Ÿ"""
        self.agents[agent.name] = agent
        print(f"â• å·²æ·»åŠ ä»£ç†: {agent.name} ({agent.role})")
    
    async def start_collaboration(self, project_goal: str, involved_agents: List[str]) -> Dict:
        """å¯åŠ¨å¤šä»£ç†åä½œ"""
        
        print(f"ğŸ¤ å¯åŠ¨å¤šä»£ç†åä½œé¡¹ç›®: {project_goal}")
        
        # è·å–ç›¸å…³ä»£ç†
        agents = [self.agents[name] for name in involved_agents if name in self.agents]
        
        if not agents:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä»£ç†"}
        
        # å¦‚æœæœ‰é¡¹ç›®ç»ç†ï¼Œè®©å®ƒæ¥åè°ƒ
        if "ProjectManager" in self.agents:
            pm = self.agents["ProjectManager"]
            collaboration_result = await pm.coordinate_project(project_goal, agents)
        else:
            # æ²¡æœ‰é¡¹ç›®ç»ç†ï¼Œç®€å•çš„ç‚¹å¯¹ç‚¹åä½œ
            collaboration_result = await self._simple_collaboration(project_goal, agents)
        
        self.active_collaborations.append({
            "goal": project_goal,
            "agents": involved_agents,
            "start_time": datetime.now().isoformat(),
            "result": collaboration_result
        })
        
        return collaboration_result
    
    async def _simple_collaboration(self, goal: str, agents: List[Agent]) -> Dict:
        """ç®€å•çš„ä»£ç†é—´åä½œ"""
        
        results = []
        
        # æ¯ä¸ªä»£ç†å¤„ç†ç›®æ ‡
        for agent in agents:
            individual_result = await agent.process_message({
                "from": "System",
                "type": "collaboration_request",
                "content": f"è¯·ä¸ºé¡¹ç›®ç›®æ ‡æä¾›ä½ çš„ä¸“ä¸šæ„è§: {goal}"
            })
            
            results.append({
                "agent": agent.name,
                "contribution": individual_result
            })
        
        return {
            "type": "simple_collaboration",
            "goal": goal,
            "contributions": results
        }
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        
        agent_status = {}
        for name, agent in self.agents.items():
            agent_status[name] = {
                "role": agent.role,
                "capabilities": agent.capabilities,
                "message_count": len(agent.collaboration_history)
            }
        
        return {
            "total_agents": len(self.agents),
            "active_collaborations": len(self.active_collaborations),
            "agents": agent_status,
            "system_uptime": "è¿è¡Œä¸­"
        }

async def main():
    """æ¼”ç¤ºå¤šä»£ç†åä½œç³»ç»Ÿ"""
    
    print("=== å¤šä»£ç†åä½œç³»ç»Ÿæ¼”ç¤º ===")
    
    # åˆ›å»ºå¤šä»£ç†ç³»ç»Ÿ
    system = MultiAgentSystem()
    
    # æ·»åŠ ä¸åŒç±»å‹çš„ä»£ç†
    system.add_agent(ProjectManager("openai"))
    system.add_agent(DataAnalyst("openai"))
    system.add_agent(TechnicalExpert("openai"))
    
    print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    status = system.get_system_status()
    print(json.dumps(status, ensure_ascii=False, indent=2))
    
    print("\n" + "="*60 + "\n")
    
    # ç¤ºä¾‹1: æ•°æ®åˆ†æé¡¹ç›®åä½œ
    print("--- é¡¹ç›®1: é”€å”®æ•°æ®åˆ†æç³»ç»Ÿ ---")
    
    result1 = await system.start_collaboration(
        "å¼€å‘ä¸€ä¸ªé”€å”®æ•°æ®åˆ†æç³»ç»Ÿï¼Œèƒ½å¤Ÿå¤„ç†å¤§é‡æ•°æ®å¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š",
        ["ProjectManager", "DataAnalyst", "TechnicalExpert"]
    )
    
    print(f"ğŸ¯ åä½œç»“æœ:")
    if "assignments" in result1:
        for assignment in result1["assignments"]:
            print(f"  {assignment['agent']}: {assignment['assignment']['action_taken']}")
    
    print("\n" + "="*60 + "\n")
    
    # ç¤ºä¾‹2: æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡
    print("--- é¡¹ç›®2: AIå®¢æœç³»ç»Ÿè®¾è®¡ ---") 
    
    # æŠ€æœ¯ä¸“å®¶ç‹¬ç«‹å·¥ä½œ
    tech_expert = system.agents["TechnicalExpert"]
    design_result = await tech_expert.design_solution(
        "è®¾è®¡ä¸€ä¸ªæ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€çŸ¥è¯†åº“æŸ¥è¯¢å’Œäººå·¥è½¬æ¥"
    )
    
    print(f"ğŸ”§ æŠ€æœ¯æ–¹æ¡ˆ:")
    print(f"æ¶æ„: {design_result['architecture']}")
    print(f"æŠ€æœ¯æ ˆ: {', '.join(design_result['technologies'])}")
    print(f"é¢„ä¼°æ—¶é—´: {design_result['timeline_estimate']}")
    
    # æ•°æ®åˆ†æå¸ˆæä¾›æ•°æ®è§†è§’
    data_analyst = system.agents["DataAnalyst"]
    data_response = await data_analyst.process_message({
        "from": "TechnicalExpert",
        "type": "consultation",
        "content": f"æŠ€æœ¯æ–¹æ¡ˆ: {json.dumps(design_result, ensure_ascii=False)}, è¯·ä»æ•°æ®åˆ†æè§’åº¦æä¾›å»ºè®®"
    })
    
    print(f"\nğŸ“Š æ•°æ®åˆ†æå¸ˆå»ºè®®: {data_response['response']}")
    
    print(f"\nğŸ¤– æœ€ç»ˆç³»ç»ŸçŠ¶æ€:")
    final_status = system.get_system_status()
    print(f"æ€»ä»£ç†æ•°: {final_status['total_agents']}")
    print(f"åä½œé¡¹ç›®æ•°: {final_status['active_collaborations']}")

if __name__ == "__main__":
    asyncio.run(main())