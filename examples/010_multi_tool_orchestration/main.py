#!/usr/bin/env python3

import asyncio
import json
import os
import sys
sys.path.append('../..')

from ai_modular_blocks import create_llm
from ai_modular_blocks.tools import Calculator, FileOperations, WebClient

class DataAnalysisWorkflow:
    """
    æ•°æ®åˆ†æå·¥ä½œæµ - åè°ƒå¤šä¸ªå·¥å…·å®Œæˆå¤æ‚ä»»åŠ¡
    
    å±•ç¤ºçº¯Pythonå¦‚ä½•ä¼˜é›…åœ°ç»„åˆå¤šä¸ªç‹¬ç«‹å·¥å…·
    """
    
    def __init__(self, provider: str = "openai"):
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.calculator = Calculator()
        self.file_ops = FileOperations()
        self.web_client = WebClient()
    
    async def analyze_financial_data(self, data_sources: dict) -> dict:
        """
        å¤šæ­¥éª¤é‡‘èæ•°æ®åˆ†æå·¥ä½œæµ:
        1. ä»å¤šä¸ªæ¥æºæ”¶é›†æ•°æ®
        2. è¿›è¡Œæ•°å­¦è®¡ç®—
        3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        4. ä¿å­˜ç»“æœ
        """
        
        print("ğŸ’° å¼€å§‹é‡‘èæ•°æ®åˆ†æå·¥ä½œæµ...")
        workflow_results = {"steps": [], "final_report": None}
        
        # æ­¥éª¤1: æ”¶é›†æ•°æ®
        print("ğŸ“Š æ­¥éª¤1: æ”¶é›†æ•°æ®")
        collected_data = {}
        
        # ä»æ–‡ä»¶è¯»å–å†å²æ•°æ®
        if "file_path" in data_sources:
            file_result = await self.file_ops.read_file(data_sources["file_path"])
            if file_result["success"]:
                try:
                    collected_data["historical"] = json.loads(file_result["content"])
                    print(f"  âœ… ä»æ–‡ä»¶è¯»å–äº†å†å²æ•°æ®")
                except:
                    collected_data["historical"] = {"error": "æ–‡ä»¶æ ¼å¼é”™è¯¯"}
                    print(f"  âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯")
        
        # ä»Web APIè·å–å®æ—¶æ•°æ®(æ¨¡æ‹Ÿ)
        if "api_urls" in data_sources:
            web_data = {}
            for name, url in data_sources["api_urls"].items():
                web_result = await self.web_client.fetch(url)
                if web_result["success"]:
                    web_data[name] = web_result["content"][:500]  # é™åˆ¶é•¿åº¦
                    print(f"  âœ… è·å–äº† {name} æ•°æ®")
            collected_data["realtime"] = web_data
        
        workflow_results["steps"].append({
            "name": "æ•°æ®æ”¶é›†",
            "status": "å®Œæˆ",
            "data": list(collected_data.keys())
        })
        
        # æ­¥éª¤2: æ•°å­¦è®¡ç®—
        print("ğŸ§® æ­¥éª¤2: æ‰§è¡Œè®¡ç®—")
        calculations = {}
        
        # ç¤ºä¾‹è®¡ç®—
        calc_expressions = [
            "100 * 1.05**5",  # å¤åˆ©è®¡ç®—
            "(200 + 300 + 150) / 3",  # å¹³å‡å€¼
            "1000 * 0.08 * 2",  # ç®€å•åˆ©æ¯
        ]
        
        for i, expr in enumerate(calc_expressions):
            calc_result = self.calculator.calculate(expr)
            if calc_result["success"]:
                calculations[f"calculation_{i+1}"] = {
                    "expression": expr,
                    "result": calc_result["result"]
                }
                print(f"  âœ… è®¡ç®—å®Œæˆ: {expr} = {calc_result['result']}")
        
        workflow_results["steps"].append({
            "name": "æ•°å­¦è®¡ç®—",
            "status": "å®Œæˆ", 
            "results": calculations
        })
        
        # æ­¥éª¤3: LLMåˆ†æ
        print("ğŸ¤– æ­¥éª¤3: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        
        analysis_data = {
            "collected_data": collected_data,
            "calculations": calculations,
            "metadata": {
                "data_sources": len(collected_data),
                "calculations_performed": len(calculations)
            }
        }
        
        analysis_prompt = f"""
åŸºäºä»¥ä¸‹è´¢åŠ¡æ•°æ®å’Œè®¡ç®—ç»“æœï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„åˆ†ææŠ¥å‘Š:

æ”¶é›†çš„æ•°æ®:
{json.dumps(collected_data, indent=2, ensure_ascii=False)}

è®¡ç®—ç»“æœ:
{json.dumps(calculations, indent=2, ensure_ascii=False)}

è¯·æä¾›:
1. æ•°æ®æ¦‚è§ˆ
2. å…³é”®å‘ç°
3. é£é™©åˆ†æ
4. æŠ•èµ„å»ºè®®

ä¿æŒä¸“ä¸šä½†æ˜“äºç†è§£ã€‚
"""
        
        report_response = await self.llm.generate(analysis_prompt)
        final_report = report_response["content"]
        
        workflow_results["steps"].append({
            "name": "LLMåˆ†æ",
            "status": "å®Œæˆ",
            "report_length": len(final_report)
        })
        
        # æ­¥éª¤4: ä¿å­˜ç»“æœ
        print("ğŸ’¾ æ­¥éª¤4: ä¿å­˜åˆ†æç»“æœ")
        
        report_data = {
            "timestamp": "2024-01-01T00:00:00Z",  # å®é™…åº”ç”¨ä¸­ä½¿ç”¨çœŸå®æ—¶é—´
            "workflow_results": workflow_results,
            "final_report": final_report,
            "raw_data": analysis_data
        }
        
        save_path = "financial_analysis_report.json"
        save_result = await self.file_ops.write_file(
            save_path, 
            json.dumps(report_data, indent=2, ensure_ascii=False)
        )
        
        if save_result["success"]:
            print(f"  âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")
            workflow_results["steps"].append({
                "name": "ä¿å­˜ç»“æœ",
                "status": "å®Œæˆ",
                "file_path": save_path
            })
        
        workflow_results["final_report"] = final_report
        return workflow_results

class ResearchPipeline:
    """
    ç ”ç©¶ç®¡é“ - è‡ªåŠ¨åŒ–ç ”ç©¶å·¥ä½œæµ
    """
    
    def __init__(self, provider: str = "openai"):
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.calculator = Calculator()
        self.file_ops = FileOperations()
        self.web_client = WebClient()
    
    async def conduct_research(self, topic: str) -> dict:
        """æ‰§è¡Œå®Œæ•´çš„ç ”ç©¶æµç¨‹"""
        
        print(f"ğŸ”¬ å¼€å§‹ç ”ç©¶ä¸»é¢˜: {topic}")
        
        # 1. ç”Ÿæˆç ”ç©¶è®¡åˆ’
        print("ğŸ“‹ ç”Ÿæˆç ”ç©¶è®¡åˆ’...")
        plan_prompt = f"""
ä¸ºä¸»é¢˜ "{topic}" åˆ¶å®šä¸€ä¸ªç ”ç©¶è®¡åˆ’ã€‚

è¯·æä¾›:
1. 3ä¸ªå…³é”®ç ”ç©¶é—®é¢˜
2. éœ€è¦æŸ¥æ‰¾çš„æ•°æ®ç±»å‹
3. å¯èƒ½éœ€è¦çš„è®¡ç®—
4. é¢„æœŸçš„ç ”ç©¶äº§å‡º

æ ¼å¼åŒ–ä¸ºJSONï¼Œæ–¹ä¾¿ç¨‹åºå¤„ç†ã€‚
"""
        
        plan_response = await self.llm.generate(plan_prompt)
        
        # 2. æ‰§è¡Œä¿¡æ¯æœç´¢ (æ¨¡æ‹Ÿ)
        print("ğŸ” æ‰§è¡Œä¿¡æ¯æœç´¢...")
        search_results = {
            "academic_papers": "æ¨¡æ‹Ÿå­¦æœ¯è®ºæ–‡æ‘˜è¦...",
            "industry_reports": "æ¨¡æ‹Ÿè¡Œä¸šæŠ¥å‘Šæ•°æ®...",
            "statistical_data": "æ¨¡æ‹Ÿç»Ÿè®¡æ•°æ®..."
        }
        
        # 3. æ•°æ®åˆ†æ (å¦‚æœéœ€è¦)
        print("ğŸ“Š æ‰§è¡Œæ•°æ®åˆ†æ...")
        analysis_results = {}
        
        # æ¨¡æ‹Ÿä¸€äº›ç›¸å…³è®¡ç®—
        if "è®¡ç®—" in topic or "æ•°æ®" in topic or "ç»Ÿè®¡" in topic:
            expressions = ["100 / 7", "2.5 * 3.14159", "sqrt(144)"]  # sqrtä¼šå¤±è´¥ï¼Œå±•ç¤ºé”™è¯¯å¤„ç†
            
            for expr in expressions:
                calc_result = self.calculator.calculate(expr)
                analysis_results[expr] = calc_result
        
        # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print("ğŸ“„ ç”Ÿæˆç ”ç©¶æŠ¥å‘Š...")
        
        research_data = {
            "topic": topic,
            "plan": plan_response["content"],
            "search_results": search_results,
            "analysis": analysis_results
        }
        
        final_prompt = f"""
åŸºäºä»¥ä¸‹ç ”ç©¶æ•°æ®ç”Ÿæˆä¸€ä»½å®Œæ•´çš„ç ”ç©¶æŠ¥å‘Š:

{json.dumps(research_data, indent=2, ensure_ascii=False)}

æŠ¥å‘Šåº”åŒ…å«:
1. æ‰§è¡Œæ‘˜è¦
2. ç ”ç©¶æ–¹æ³•
3. ä¸»è¦å‘ç°
4. ç»“è®ºå’Œå»ºè®®

ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ä½†æ˜“äºç†è§£ã€‚
"""
        
        final_response = await self.llm.generate(final_prompt)
        
        # 5. ä¿å­˜ç ”ç©¶æŠ¥å‘Š
        report_filename = f"research_report_{topic.replace(' ', '_')}.md"
        await self.file_ops.write_file(report_filename, final_response["content"])
        
        return {
            "topic": topic,
            "plan": plan_response["content"],
            "report_file": report_filename,
            "report_preview": final_response["content"][:500] + "...",
            "data_analyzed": len(analysis_results),
            "sources_searched": len(search_results)
        }

async def main():
    """æ¼”ç¤ºå¤šå·¥å…·åè°ƒçš„å¤æ‚å·¥ä½œæµ"""
    
    # ç¤ºä¾‹1: é‡‘èæ•°æ®åˆ†æå·¥ä½œæµ
    print("=== ç¤ºä¾‹1: é‡‘èæ•°æ®åˆ†æå·¥ä½œæµ ===")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®æ–‡ä»¶
    sample_data = {
        "monthly_returns": [0.05, 0.03, -0.02, 0.07, 0.04],
        "portfolio_value": 100000,
        "risk_level": "moderate"
    }
    
    file_ops = FileOperations()
    await file_ops.write_file("sample_financial_data.json", json.dumps(sample_data))
    
    workflow = DataAnalysisWorkflow("openai")
    
    data_sources = {
        "file_path": "sample_financial_data.json",
        "api_urls": {
            "market_data": "https://api.example.com/market",  # æ¨¡æ‹ŸURL
            "news_feed": "https://api.example.com/news"       # æ¨¡æ‹ŸURL
        }
    }
    
    workflow_result = await workflow.analyze_financial_data(data_sources)
    
    print(f"ğŸ“Š å·¥ä½œæµå®Œæˆ!")
    print(f"æ‰§è¡Œæ­¥éª¤: {len(workflow_result['steps'])}")
    for step in workflow_result["steps"]:
        print(f"  - {step['name']}: {step['status']}")
    print(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Š: {workflow_result['final_report'][:200]}...")
    
    print("\n" + "="*60 + "\n")
    
    # ç¤ºä¾‹2: ç ”ç©¶ç®¡é“
    print("=== ç¤ºä¾‹2: è‡ªåŠ¨åŒ–ç ”ç©¶ç®¡é“ ===")
    
    pipeline = ResearchPipeline("openai")
    research_result = await pipeline.conduct_research("äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨")
    
    print(f"ğŸ”¬ ç ”ç©¶å®Œæˆ!")
    print(f"ä¸»é¢˜: {research_result['topic']}")
    print(f"åˆ†ææ•°æ®ç‚¹: {research_result['data_analyzed']}")
    print(f"æœç´¢æ¥æº: {research_result['sources_searched']}")
    print(f"æŠ¥å‘Šæ–‡ä»¶: {research_result['report_file']}")
    print(f"ğŸ“‹ æŠ¥å‘Šé¢„è§ˆ:\n{research_result['report_preview']}")

if __name__ == "__main__":
    asyncio.run(main())