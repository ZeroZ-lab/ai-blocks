#!/usr/bin/env python3

import asyncio
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any

sys.path.append('../..')

from ai_modular_blocks import create_llm
from ai_modular_blocks.tools import Calculator, FileOperations

class SelfImprovingAgent:
    """
    è‡ªæˆ‘æ”¹è¿›ä»£ç† - é€šè¿‡åæ€å’Œå­¦ä¹ æå‡æ€§èƒ½
    
    çº¯Pythonå®ç°ï¼Œç”¨æˆ·å®Œå…¨æ§åˆ¶æ”¹è¿›é€»è¾‘
    """
    
    def __init__(self, provider: str = "openai"):
        self.llm = create_llm(provider, api_key=os.getenv(f"{provider.upper()}_API_KEY"))
        self.calculator = Calculator()
        self.file_ops = FileOperations()
        
        # æ€§èƒ½è·Ÿè¸ª
        self.performance_log = []
        self.learned_patterns = {}
        self.improvement_history = []
        
        # çŸ¥è¯†åº“
        self.knowledge_base = {
            "successful_strategies": [],
            "common_mistakes": [],
            "optimization_tips": []
        }
    
    async def execute_task_with_reflection(self, task: str) -> Dict:
        """æ‰§è¡Œä»»åŠ¡å¹¶è¿›è¡Œåæ€æ”¹è¿›"""
        
        print(f"ğŸ¯ æ‰§è¡Œä»»åŠ¡: {task}")
        start_time = datetime.now()
        
        # 1. åŸºäºå†å²ç»éªŒä¼˜åŒ–ä»»åŠ¡æ‰§è¡Œ
        optimized_approach = await self._optimize_approach(task)
        print(f"ğŸ’¡ ä¼˜åŒ–ç­–ç•¥: {optimized_approach['strategy']}")
        
        # 2. æ‰§è¡Œä»»åŠ¡
        result = await self._execute_with_monitoring(task, optimized_approach)
        
        # 3. æ€§èƒ½åæ€
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        reflection = await self._reflect_on_performance(task, result, execution_time)
        
        # 4. å­¦ä¹ å’Œæ”¹è¿›
        await self._learn_from_experience(task, result, reflection)
        
        return {
            "task": task,
            "result": result,
            "execution_time": execution_time,
            "reflection": reflection,
            "improvements_learned": len(self.improvement_history)
        }
    
    async def _optimize_approach(self, task: str) -> Dict:
        """åŸºäºå†å²ç»éªŒä¼˜åŒ–æ‰§è¡Œæ–¹æ³•"""
        
        # æŸ¥æ‰¾ç›¸ä¼¼ä»»åŠ¡çš„æˆåŠŸç­–ç•¥
        similar_patterns = []
        for pattern in self.learned_patterns.get("successful", []):
            if any(keyword in task.lower() for keyword in pattern.get("keywords", [])):
                similar_patterns.append(pattern)
        
        context = ""
        if similar_patterns:
            context = f"å†å²æˆåŠŸç­–ç•¥: {json.dumps(similar_patterns[-3:], ensure_ascii=False)}"
        
        optimization_prompt = f"""
ä»»åŠ¡: {task}
{context}

åŸºäºå†å²ç»éªŒå’Œæœ€ä½³å®è·µï¼Œè¯·æä¾›ä¼˜åŒ–çš„æ‰§è¡Œç­–ç•¥:

è¿”å›JSON:
{{
  "strategy": "å…·ä½“ç­–ç•¥æè¿°",
  "key_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
  "potential_risks": ["é£é™©1", "é£é™©2"],
  "success_metrics": ["æŒ‡æ ‡1", "æŒ‡æ ‡2"]
}}
"""
        
        response = await self.llm.generate(optimization_prompt)
        
        try:
            content = response["content"].strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            return json.loads(content)
        except:
            return {
                "strategy": "æ ‡å‡†æ‰§è¡Œæµç¨‹",
                "key_steps": ["åˆ†æä»»åŠ¡", "æ‰§è¡Œæ“ä½œ", "éªŒè¯ç»“æœ"],
                "potential_risks": ["æ‰§è¡Œå¤±è´¥"],
                "success_metrics": ["ä»»åŠ¡å®Œæˆ"]
            }
    
    async def _execute_with_monitoring(self, task: str, approach: Dict) -> Dict:
        """æ‰§è¡Œä»»åŠ¡å¹¶ç›‘æ§æ€§èƒ½"""
        
        try:
            # ç®€åŒ–çš„ä»»åŠ¡æ‰§è¡Œé€»è¾‘
            if "è®¡ç®—" in task or "æ•°å­¦" in task:
                # æå–å¹¶æ‰§è¡Œæ•°å­¦è®¡ç®—
                calc_prompt = f"ä»ä»»åŠ¡ä¸­æå–æ•°å­¦è¡¨è¾¾å¼: {task}"
                calc_response = await self.llm.generate(calc_prompt)
                
                # ç®€å•æå–é€»è¾‘
                import re
                numbers = re.findall(r'\d+(?:\.\d+)?', task)
                if len(numbers) >= 2:
                    expr = f"{numbers[0]} + {numbers[1]}"  # ç®€åŒ–ç¤ºä¾‹
                    calc_result = self.calculator.calculate(expr)
                    if calc_result["success"]:
                        return {
                            "success": True,
                            "result": calc_result["result"],
                            "method": "æ•°å­¦è®¡ç®—",
                            "details": f"è®¡ç®—äº† {expr} = {calc_result['result']}"
                        }
            
            # é€šç”¨ä»»åŠ¡å¤„ç†
            execution_prompt = f"""
æ‰§è¡Œä»»åŠ¡: {task}
ç­–ç•¥: {approach['strategy']}

è¯·æä¾›æ‰§è¡Œç»“æœå’Œè¯¦ç»†è¿‡ç¨‹ã€‚
"""
            
            response = await self.llm.generate(execution_prompt)
            
            return {
                "success": True,
                "result": response["content"][:500],
                "method": "LLMåˆ†æ",
                "details": "é€šè¿‡è¯­è¨€æ¨¡å‹å®Œæˆä»»åŠ¡åˆ†æ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "method": "å¼‚å¸¸å¤„ç†",
                "details": f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            }
    
    async def _reflect_on_performance(self, task: str, result: Dict, execution_time: float) -> Dict:
        """åæ€ä»»åŠ¡æ‰§è¡Œçš„æ€§èƒ½"""
        
        reflection_prompt = f"""
åˆšæ‰æ‰§è¡Œäº†ä»»åŠ¡: {task}
æ‰§è¡Œç»“æœ: {json.dumps(result, ensure_ascii=False)}
æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’

è¯·åæ€è¿™æ¬¡æ‰§è¡Œçš„è¡¨ç°:

è¿”å›JSON:
{{
  "performance_rating": 8,
  "what_went_well": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
  "what_could_improve": ["æ”¹è¿›ç‚¹1", "æ”¹è¿›ç‚¹2"],
  "key_learnings": ["å­¦ä¹ ç‚¹1", "å­¦ä¹ ç‚¹2"],
  "optimization_suggestions": ["å»ºè®®1", "å»ºè®®2"]
}}
"""
        
        response = await self.llm.generate(reflection_prompt)
        
        try:
            content = response["content"].strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            reflection = json.loads(content)
            
            # è®°å½•æ€§èƒ½
            self.performance_log.append({
                "task": task,
                "rating": reflection.get("performance_rating", 5),
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat()
            })
            
            return reflection
            
        except:
            return {
                "performance_rating": 5,
                "what_went_well": ["ä»»åŠ¡å®Œæˆ"],
                "what_could_improve": ["æé«˜æ•ˆç‡"],
                "key_learnings": ["ç§¯ç´¯ç»éªŒ"],
                "optimization_suggestions": ["ä¼˜åŒ–æµç¨‹"]
            }
    
    async def _learn_from_experience(self, task: str, result: Dict, reflection: Dict):
        """ä»ç»éªŒä¸­å­¦ä¹ """
        
        # æå–ä»»åŠ¡å…³é”®è¯
        task_keywords = task.lower().split()[:5]
        
        # å¦‚æœæ€§èƒ½è‰¯å¥½ï¼Œè®°å½•æˆåŠŸæ¨¡å¼
        if reflection.get("performance_rating", 0) >= 7:
            success_pattern = {
                "task_type": task[:50],
                "keywords": task_keywords,
                "strategy": result.get("method", "unknown"),
                "success_factors": reflection.get("what_went_well", []),
                "timestamp": datetime.now().isoformat()
            }
            
            if "successful" not in self.learned_patterns:
                self.learned_patterns["successful"] = []
            self.learned_patterns["successful"].append(success_pattern)
            
            # é™åˆ¶å­˜å‚¨æ•°é‡
            if len(self.learned_patterns["successful"]) > 20:
                self.learned_patterns["successful"] = self.learned_patterns["successful"][-20:]
        
        # è®°å½•æ”¹è¿›å»ºè®®
        improvements = reflection.get("optimization_suggestions", [])
        if improvements:
            self.improvement_history.append({
                "task": task,
                "improvements": improvements,
                "timestamp": datetime.now().isoformat()
            })
        
        # æ›´æ–°çŸ¥è¯†åº“
        self.knowledge_base["successful_strategies"].extend(
            reflection.get("what_went_well", [])
        )
        self.knowledge_base["optimization_tips"].extend(
            reflection.get("optimization_suggestions", [])
        )
        
        # é™åˆ¶çŸ¥è¯†åº“å¤§å°
        for category in self.knowledge_base:
            if len(self.knowledge_base[category]) > 50:
                self.knowledge_base[category] = self.knowledge_base[category][-50:]
    
    def get_improvement_summary(self) -> Dict:
        """è·å–è‡ªæˆ‘æ”¹è¿›çš„æ‘˜è¦"""
        
        # è®¡ç®—å¹³å‡æ€§èƒ½è¯„åˆ†
        ratings = [log["rating"] for log in self.performance_log]
        avg_rating = sum(ratings) / len(ratings) if ratings else 0
        
        # æœ€è¿‘çš„æ”¹è¿›è¶‹åŠ¿
        recent_ratings = ratings[-10:] if len(ratings) >= 10 else ratings
        recent_avg = sum(recent_ratings) / len(recent_ratings) if recent_ratings else 0
        
        return {
            "total_tasks": len(self.performance_log),
            "average_performance": round(avg_rating, 2),
            "recent_performance": round(recent_avg, 2),
            "improvement_trend": "ä¸Šå‡" if recent_avg > avg_rating else "ç¨³å®š",
            "learned_patterns": len(self.learned_patterns.get("successful", [])),
            "knowledge_base_size": {
                category: len(items) for category, items in self.knowledge_base.items()
            },
            "top_strategies": self.knowledge_base["successful_strategies"][-5:],
            "recent_optimizations": [h["improvements"] for h in self.improvement_history[-3:]]
        }

async def main():
    """æ¼”ç¤ºè‡ªæˆ‘æ”¹è¿›ä»£ç†"""
    
    print("=== è‡ªæˆ‘æ”¹è¿›ä»£ç†æ¼”ç¤º ===")
    
    agent = SelfImprovingAgent("openai")
    
    # æ‰§è¡Œä¸€ç³»åˆ—ä»»åŠ¡ï¼Œè§‚å¯Ÿè‡ªæˆ‘æ”¹è¿›è¿‡ç¨‹
    tasks = [
        "è®¡ç®— 100 å’Œ 200 çš„å’Œ",
        "åˆ†ææ•°å­—åºåˆ— 1, 4, 9, 16 çš„è§„å¾‹",
        "è®¡ç®— 50 ä¹˜ä»¥ 3 çš„ç»“æœ",
        "è§£é‡Šä»€ä¹ˆæ˜¯å¤åˆ©æ•ˆåº”",
        "è®¡ç®— 15 çš„å¹³æ–¹æ ¹"
    ]
    
    print("å¼€å§‹æ‰§è¡Œä»»åŠ¡åºåˆ—ï¼Œè§‚å¯Ÿä»£ç†çš„è‡ªæˆ‘æ”¹è¿›...\n")
    
    for i, task in enumerate(tasks, 1):
        print(f"--- ä»»åŠ¡ {i} ---")
        
        result = await agent.execute_task_with_reflection(task)
        
        print(f"æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f}ç§’")
        print(f"æ€§èƒ½è¯„åˆ†: {result['reflection']['performance_rating']}/10")
        print(f"æˆåŠŸå› ç´ : {result['reflection']['what_went_well']}")
        print(f"æ”¹è¿›å»ºè®®: {result['reflection']['optimization_suggestions']}")
        print()
    
    # æ˜¾ç¤ºå­¦ä¹ æˆæœ
    print("="*60)
    print("ğŸ§  è‡ªæˆ‘æ”¹è¿›æ€»ç»“:")
    
    summary = agent.get_improvement_summary()
    print(f"æ€»ä»»åŠ¡æ•°: {summary['total_tasks']}")
    print(f"å¹³å‡æ€§èƒ½: {summary['average_performance']}/10")
    print(f"æœ€è¿‘æ€§èƒ½: {summary['recent_performance']}/10")
    print(f"æ”¹è¿›è¶‹åŠ¿: {summary['improvement_trend']}")
    print(f"å­¦ä¼šçš„æ¨¡å¼: {summary['learned_patterns']} ä¸ª")
    
    print(f"\nğŸ“š çŸ¥è¯†åº“å¤§å°:")
    for category, size in summary['knowledge_base_size'].items():
        print(f"  {category}: {size} é¡¹")
    
    print(f"\nğŸ† é¡¶çº§ç­–ç•¥:")
    for strategy in summary['top_strategies'][-3:]:
        print(f"  â€¢ {strategy}")

if __name__ == "__main__":
    asyncio.run(main())