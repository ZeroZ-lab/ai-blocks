#!/usr/bin/env python3
"""
å¤šProvideræ¯”è¾ƒç¤ºä¾‹

å±•ç¤ºå¦‚ä½•åŒæ—¶ä½¿ç”¨å¤šä¸ªLLMæä¾›å•†å¹¶æ¯”è¾ƒå“åº”ã€‚
çœŸå®åœºæ™¯ä¸­å¾ˆæœ‰ç”¨çš„åŠŸèƒ½ã€‚
"""

import asyncio
import os
from ai_modular_blocks.providers.llm import LLMProviderFactory
from ai_modular_blocks.core.types import LLMConfig, ChatMessage


async def compare_providers():
    """æ¯”è¾ƒä¸åŒproviderçš„å“åº”"""
    
    LLMProviderFactory.initialize()
    
    # æ£€æŸ¥API keys
    providers_config = []
    
    if os.getenv("OPENAI_API_KEY"):
        providers_config.append({
            "name": "OpenAI",
            "provider": "openai",
            "config": LLMConfig(
                provider="openai",
                model="gpt-3.5-turbo",
                api_key=os.getenv("OPENAI_API_KEY"),
                max_tokens=100,
                temperature=0.7
            )
        })
    
    if os.getenv("ANTHROPIC_API_KEY"):
        providers_config.append({
            "name": "Anthropic",
            "provider": "anthropic", 
            "config": LLMConfig(
                provider="anthropic",
                model="claude-3-haiku-20240307",
                api_key=os.getenv("ANTHROPIC_API_KEY"),
                max_tokens=100,
                temperature=0.7
            )
        })
    
    if not providers_config:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„API keysï¼Œè¯·è®¾ç½®OPENAI_API_KEYæˆ–ANTHROPIC_API_KEY")
        return
    
    # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
    test_message = [
        ChatMessage(role="user", content="ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½")
    ]
    
    print("ğŸ§ª åŒä¸€ä¸ªé—®é¢˜ï¼Œä¸åŒProviderçš„å›ç­”å¯¹æ¯”:")
    print(f"â“ é—®é¢˜: {test_message[0].content}")
    print("-" * 50)
    
    # å¹¶å‘è°ƒç”¨æ‰€æœ‰å¯ç”¨çš„providers
    tasks = []
    for config in providers_config:
        provider = LLMProviderFactory.create_provider(config["provider"], config["config"])
        task = asyncio.create_task(
            call_provider_with_name(provider, config["name"], test_message)
        )
        tasks.append(task)
    
    # ç­‰å¾…æ‰€æœ‰ç»“æœ
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for result in results:
        if isinstance(result, Exception):
            print(f"âŒ é”™è¯¯: {result}")


async def call_provider_with_name(provider, name, messages):
    """è°ƒç”¨providerå¹¶æ ¼å¼åŒ–è¾“å‡º"""
    try:
        response = await provider.generate(messages)
        print(f"ğŸ¤– {name}: {response.content}")
        print(f"   Token: {response.usage}")
        print()
    except Exception as e:
        print(f"âŒ {name} é”™è¯¯: {e}")
        print()


if __name__ == "__main__":
    print("=== AI Modular Blocks - Provideræ¯”è¾ƒç¤ºä¾‹ ===")
    asyncio.run(compare_providers())
